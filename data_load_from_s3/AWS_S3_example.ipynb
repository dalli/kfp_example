{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ed2de7",
   "metadata": {},
   "source": [
    "# AWS S3 활용하기\n",
    "\n",
    "tensorflow에서 제공해주는 데이터가 아닌 직접 수집한 데이터를 활용하는 경우가 더 많습니다.<br>\n",
    "본 예제에서는 S3에 저장된 kaggle에서 제공하는 개와 고양이 사진 데이터를 활용하여 모델 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66925dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import components, dsl\n",
    "from kfp.components import InputPath, OutputPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8e1cb3",
   "metadata": {},
   "source": [
    "## S3 정보\n",
    "\n",
    "예제 진행에 앞서 S3를 사용하기 위해 필요한 정보들을 가져옵니다.\n",
    "access key 및 secret access key 는 다음을 참고합니다.<br>\n",
    "참고 : https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_credentials_access-keys.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf72c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    aws_access_key = 'xxxxxxxxxxxxxxxxx'\n",
    "    aws_secret_access_key = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "    bucket_name = [bucket name]\n",
    "    bucket_dir_name = [bucket directory] #data 저장 경로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdfd59b",
   "metadata": {},
   "source": [
    "access key, secret access key, bucket 이름, bucket 내 경로 정보를 가져옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2770ef6e",
   "metadata": {},
   "source": [
    "## S3에서 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b5740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_load_from_s3(\n",
    "        output_dataset_train_data: OutputPath(str)\n",
    "):\n",
    "    import boto3\n",
    "    import os\n",
    "    aws_access_key = 'xxxxxxxxxxxxxxxxx'\n",
    "    aws_secret_access_key = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "    bucket_name = [bucket name]\n",
    "    bucket_dir_name = [bucket directory] #data 저장 경로\n",
    "\n",
    "    s3r = boto3.resource('s3', aws_access_key_id=aws_access_key,\n",
    "                         aws_secret_access_key=aws_secret_access_key)\n",
    "    bucket = s3r.Bucket(bucket_name)\n",
    "    s3 = boto3.client('s3', aws_access_key_id=aws_access_key,\n",
    "                      aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "    count_dog = 0\n",
    "    count_cat = 0\n",
    "\n",
    "    os.makedirs(output_dataset_train_data)\n",
    "    for object in bucket.objects.filter(Prefix=bucket_dir_name):\n",
    "        if 'cat' in object.key :\n",
    "            temp = f'{output_dataset_train_data}/cat_{count_cat}.jpg'\n",
    "            s3.download_file(bucket_name, object.key, temp)\n",
    "            count_cat += 1\n",
    "        elif 'dog' in object.key :\n",
    "            temp = f'{output_dataset_train_data}/dog_{count_dog}.jpg'\n",
    "            s3.download_file(bucket_name, object.key, temp)\n",
    "            count_dog += 1\n",
    "\n",
    "\n",
    "train_data_load_op = components.create_component_from_func(\n",
    "    train_data_load_from_s3, base_image='python:3.9',\n",
    "    packages_to_install=['boto3']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d605cfc",
   "metadata": {},
   "source": [
    "S3 정보를 바탕으로 boto3 패키지를 활용해 데이터를 가져옵니다. 컴포넌트 간 주고 받는 데이터 경로에 S3에서 가져온 데이터를 저장합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a7cf67",
   "metadata": {},
   "source": [
    "## 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c766735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checked_data_image_list(\n",
    "        pre_data:InputPath(str)\n",
    "):\n",
    "    import os\n",
    "    file_list = os.listdir(pre_data)\n",
    "    dog_list = []\n",
    "    cat_list = []\n",
    "    for i, item in enumerate(file_list):\n",
    "        if 'cat' in item :\n",
    "            dog_list.append(item)\n",
    "        elif 'dog' in item :\n",
    "            cat_list.append(item)\n",
    "\n",
    "    print(f'train_dog_image_num : {len(dog_list)}')\n",
    "    print(f'train_cat_image_num : {len(cat_list)}')\n",
    "\n",
    "checked_data_image_list_op = components.create_component_from_func(\n",
    "    checked_data_image_list, base_image='python:3.9'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fdc42f",
   "metadata": {},
   "source": [
    "데이터가 정상적으로 저장되었는지 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cdf7df",
   "metadata": {},
   "source": [
    "## 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(\n",
    "        pre_data: InputPath(str),\n",
    "        train_data: OutputPath('Dataset')\n",
    "):\n",
    "    from skimage import io\n",
    "    from skimage.transform import resize\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "\n",
    "    file_list = os.listdir(pre_data)\n",
    "    train_list = []\n",
    "    label_list = []\n",
    "    for i, item in enumerate(file_list):\n",
    "        temp = f'{pre_data}/{item}'\n",
    "        img = io.imread(temp)\n",
    "        resize_img = resize(img,(224,224))\n",
    "        resize_img = np.array(resize_img)\n",
    "        train_list.append(resize_img)\n",
    "        if 'cat' in item :\n",
    "            label_list.append([1,0])\n",
    "        elif 'dog' in item :\n",
    "            label_list.append([0,1])\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(columns=['image', 'label'])\n",
    "    for i, image in enumerate(train_list):\n",
    "        df.loc[i] = ({'image': image, 'label': label_list[i]})\n",
    "\n",
    "    with open(train_data, 'wb') as f:\n",
    "        pickle.dump(df, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "data_generation_op = components.create_component_from_func(\n",
    "    data_generation, base_image='python:3.9',\n",
    "    packages_to_install=['numpy', 'scikit-image', 'pandas']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a36a5d5",
   "metadata": {},
   "source": [
    "저장된 이미지 데이터를 읽어와서 전처리를 통해 학습할 수 있는 데이터셋을 생성합니다. <br>\n",
    "생성된 데이터셋은 pickle 파일로 저장합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4707e9e3",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841973f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generation(\n",
    "        pretrain_model : OutputPath('TFModel')\n",
    ") :\n",
    "    from keras.applications import ResNet50\n",
    "    from keras.models import Sequential\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(ResNet50(include_top=True, weights=None, input_shape=(224, 224, 3), classes=2))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.save(pretrain_model)\n",
    "\n",
    "model_generation_op = components.create_component_from_func(\n",
    "    model_generation, base_image='tensorflow/tensorflow'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b64dd70",
   "metadata": {},
   "source": [
    "이미지 분류 모델로 ResNet50을 활용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cbdc2c",
   "metadata": {},
   "source": [
    "## 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87aa4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        train_dataset: InputPath('Dataset'),\n",
    "        pre_model: InputPath('TFModel'),\n",
    "        trained_model : OutputPath('TFModel')\n",
    ") :\n",
    "    import pickle\n",
    "    from tensorflow import keras\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    with open(train_dataset, 'rb') as file:\n",
    "        tr_data = pickle.load(file)\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i, item in enumerate(tr_data['image']) :\n",
    "        images.append(item)\n",
    "        labels.append(tr_data['label'][i])\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    model = keras.models.load_model(pre_model)\n",
    "\n",
    "    model.fit(images, labels, epochs=200)\n",
    "    model.save(trained_model)\n",
    "\n",
    "train_result_op = components.create_component_from_func(\n",
    "    train_model,\n",
    "    base_image='tensorflow/tensorflow',\n",
    "    packages_to_install=['pandas==1.4.2']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddd8a79",
   "metadata": {},
   "source": [
    "pickle 형태로 저장된 데이터셋과 ResNet50 모델을 입력받아 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb205f",
   "metadata": {},
   "source": [
    "## 파이프라인 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name='example data load from s3 and train')\n",
    "def aws_dog_cat_classification_pipeline():\n",
    "    train_data_load_task = train_data_load_op()\n",
    "    checked_data_image_list_task = checked_data_image_list_op(train_data_load_task.outputs['output_dataset_train_data'])\n",
    "    model_generation_task = model_generation_op()\n",
    "    data_generation_task = data_generation_op(train_data_load_task.outputs['output_dataset_train_data'])\n",
    "    train_task = train_result_op(\n",
    "        data_generation_task.outputs['train_data'],\n",
    "        model_generation_task.outputs['pretrain_model']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30922511",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(aws_dog_cat_classification_pipeline, 'data_load_from_s3.yaml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
